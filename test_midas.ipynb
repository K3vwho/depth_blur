{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kevinstoesser/opt/anaconda3/envs/torch-gpu/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "from PIL import Image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/kevinstoesser/.cache/torch/hub/intel-isl_MiDaS_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading weights:  None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/kevinstoesser/.cache/torch/hub/facebookresearch_WSL-Images_main\n",
      "Using cache found in /Users/kevinstoesser/.cache/torch/hub/intel-isl_MiDaS_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading weights:  None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/kevinstoesser/.cache/torch/hub/facebookresearch_WSL-Images_main\n",
      "Using cache found in /Users/kevinstoesser/.cache/torch/hub/intel-isl_MiDaS_master\n"
     ]
    }
   ],
   "source": [
    "midas = torch.hub.load(\"intel-isl/MiDaS\", \"MiDaS\")\n",
    "\n",
    "use_large_model = True\n",
    "\n",
    "if use_large_model:\n",
    "    midas = torch.hub.load(\"intel-isl/MiDaS\", \"MiDaS\")\n",
    "else:\n",
    "    midas = torch.hub.load(\"intel-isl/MiDaS\", \"MiDaS_small\")\n",
    "\n",
    "device = \"cpu\"\n",
    "midas.to(device)\n",
    "\n",
    "midas_transforms = torch.hub.load(\"intel-isl/MiDaS\", \"transforms\")\n",
    "\n",
    "if use_large_model:\n",
    "    transform = midas_transforms.default_transform\n",
    "else:\n",
    "    transform = midas_transforms.small_transform\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def depth(img):\n",
    "    cv_image = np.array(img)\n",
    "    img = cv2.cvtColor(cv_image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    input_batch = transform(img).to(device)\n",
    "    with torch.no_grad():\n",
    "        prediction = midas(input_batch)\n",
    "\n",
    "        prediction = torch.nn.functional.interpolate(\n",
    "            prediction.unsqueeze(1),\n",
    "            size=img.shape[:2],\n",
    "            mode=\"bicubic\",\n",
    "            align_corners=False,\n",
    "        ).squeeze()\n",
    "\n",
    "    output = prediction.cpu().numpy()\n",
    "    formatted = (output * 255 / np.max(output)).astype('uint8')\n",
    "    img = Image.fromarray(formatted)\n",
    "    return img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = '/Users/kevinstoesser/Pictures/Jan_Rotholz/DSCF3616_neural_filter.jpg'\n",
    "test_img = Image.open(image_path)\n",
    "test_depth = depth(test_img)\n",
    "test_depth.show()\n",
    "test_depth = np.array(test_depth)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image was resized\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Parameter\n",
    "resize = True\n",
    "resize_factor = 6\n",
    "\n",
    "blur_factor = 10\n",
    "target_depth = 1\n",
    "\n",
    "# Read in the image and depth map\n",
    "image = cv2.imread(image_path)\n",
    "depth_map = test_depth\n",
    "\n",
    "# resize for faster test inference\n",
    "if resize:\n",
    "    image = cv2.resize(\n",
    "        image, [int(image.shape[1]/resize_factor), int(image.shape[0]/resize_factor)])\n",
    "    depth_map = cv2.resize(\n",
    "        depth_map,  [int(depth_map.shape[1]/resize_factor), int(depth_map.shape[0]/resize_factor)])\n",
    "    print('image was resized')\n",
    "\n",
    "# Convert the depth map to a floating point numpy array with values between 0 and 1\n",
    "depth_map = depth_map / 255.0\n",
    "\n",
    "# Create an empty output image of the same size as the input\n",
    "output = np.zeros_like(image)\n",
    "\n",
    "# Calculate the kernel sizes for all pixels based on the difference between their depth values and the target depth\n",
    "kernel_sizes = (np.abs(depth_map - target_depth) * 10 + 1).astype(int)\n",
    "# print(kernel_sizes.shape)\n",
    "kernel_sizes[kernel_sizes % 2 == 0] += 1  # kernel size must be odd\n",
    "\n",
    "# Create an empty output image of the same size as the input\n",
    "output = np.zeros_like(image)\n",
    "\n",
    "# Loop over each pixel in the image\n",
    "for y in range(image.shape[0]):\n",
    "    for x in range(image.shape[1]):\n",
    "        # Get the kernel size for the current pixel\n",
    "        kernel_size = kernel_sizes[y, x]\n",
    "\n",
    "        # Apply a Gaussian blur to the image using the calculated kernel size\n",
    "        blur = cv2.GaussianBlur(image, (kernel_size, kernel_size), 0)\n",
    "\n",
    "        # Set the output pixel to the blurred value\n",
    "        output[y, x] = blur[y, x]\n",
    "\n",
    "# Save the output image\n",
    "cv2.imwrite(\"output.jpg\", output)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e4bc181c76fe971e46d1f70f95b9f723f48bcf87efd6d67cd80347a516a8ef6b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
